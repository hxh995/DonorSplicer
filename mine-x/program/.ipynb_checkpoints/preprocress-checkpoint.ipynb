{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "olympic-pitch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import import_ipynb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import load_sequence,replace_base\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "anonymous-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练集和测试集的目录\n",
    "training_set_path='../data/Training Set'\n",
    "testing_set_path='../data/Testing Set'\n",
    "\n",
    "class sequence_df:\n",
    "    def __init__(self,seq_set,chunk_size):\n",
    "        self.seq_set=seq_set;\n",
    "        self.chunk_size=chunk_size;\n",
    "        self.half_ck=int((chunk_size-1) / 2);\n",
    "        self.base_matrix=np.eye(4,dtype=np.int);\n",
    "        self.df=''\n",
    "    \n",
    "    #编码特征序列\n",
    "    def feature_code(self,seqs):\n",
    "        seqs=seqs.replace('a','0').replace('c','1').replace('t','2').replace('g','3');\n",
    "        #print(\"seqs are {}\".format(seqs));\n",
    "        seqs_code=np.concatenate([self.base_matrix[int(i)] for i in seqs]);\n",
    "        return seqs_code;\n",
    "   #过滤自身错码碱基\n",
    "    def filter_base(self,seqs):\n",
    "        match_base=re.compile(pattern='[a-z]');\n",
    "        seqs=[seq for seq in seqs if len(seq)==self.chunk_size and match_base.findall(string=replace_base(seq))== [] and replace_base(seq)!=\"\"]\n",
    "        return seqs;\n",
    "        \n",
    "    #提取特征值:将Accept_sites Donor_sites 用列表的形式取出来\n",
    "    def feature_df(self):\n",
    "        seq_df=load_sequence(self.seq_set);\n",
    "        seq_df['Accept_sites']=seq_df['ADS'].apply(lambda x:{int(i.split('..')[0]) for i in x.split(',')})\n",
    "        seq_df['Donor_sites']=seq_df['ADS'].apply(lambda x:{int(i.split('..')[1]) for i in x.split(',')})\n",
    "        seq_df['Ordinary_sites']=seq_df.apply(lambda x:set(range(self.half_ck+1,len(x['sequence'])-self.half_ck))-x['Accept_sites']-x['Donor_sites'],axis=1);\n",
    "        #获取Accept,Donor,Ordinary的sequence的序列\n",
    "        tqdm.pandas(desc=\"processing\")\n",
    "        seq_df['Donor_seqs']=seq_df.progress_apply(lambda x:np.array([x['sequence'][i-self.half_ck:i+self.half_ck+1] for i in x['Donor_sites']]),axis=1);\n",
    "        seq_df['Accept_seqs']=seq_df.progress_apply(lambda x:np.array([x['sequence'][i-self.half_ck:i+self.half_ck+1] for i in x['Accept_sites']]),axis=1);\n",
    "        seq_df['Ordinary_seqs']=seq_df.progress_apply(lambda x:np.array([x['sequence'][i-self.half_ck:i+self.half_ck+1] for i in x['Ordinary_sites']]),axis=1);\n",
    "        #过滤所有不符合要求的seqs\n",
    "        seq_df['Donor_seqs']=seq_df['Donor_seqs'].progress_apply(lambda x:self.filter_base(x));\n",
    "        seq_df['Accept_seqs']=seq_df['Accept_seqs'].progress_apply(lambda x:self.filter_base(x));\n",
    "        seq_df['Ordinary_seqs']=seq_df['Ordinary_seqs'].progress_apply(lambda x:self.filter_base(x));\n",
    "        #将序列编码 方便后续模型操作\n",
    "        seq_df['Donor_code']=seq_df.progress_apply(lambda x: np.array([self.feature_code(i) for i in x['Donor_seqs']]),axis=1);\n",
    "        seq_df['Accept_code']=seq_df.progress_apply(lambda x: np.array([self.feature_code(i) for i in x['Accept_seqs']]),axis=1);\n",
    "        seq_df['Ordinary_code']=seq_df.progress_apply(lambda x: np.array([self.feature_code(i) for i in x['Ordinary_seqs']]),axis=1);\n",
    "        #将seq_df 本身赋值于自身\n",
    "        self.df=seq_df;\n",
    "        return seq_df;\n",
    "    # to save sequence_df\n",
    "    def to_save(self,path):\n",
    "        if self.df.empty:\n",
    "            print(\"nothing to save,please run object.feature_df first\")\n",
    "            return;\n",
    "        else:\n",
    "            data=pd.DataFrame();\n",
    "            concat=np.concatenate\n",
    "            data_Doseq=concat(self.df['Donor_seqs']);\n",
    "            data_Acseq=concat(self.df['Accept_seqs']);\n",
    "            data_Orseq=concat(self.df['Ordinary_seqs']);\n",
    "            choose_index=concat((np.ones(int(1e5),dtype=int),np.zeros(len(data_Orseq)-int(1e5),dtype=int))).astype(bool);\n",
    "            np.random.shuffle(choose_index);\n",
    "            data['seqs']=concat((data_Doseq,data_Acseq,data_Orseq[choose_index]));\n",
    "            data_Docode=concat(self.df['Donor_code']);\n",
    "            data_Accode=concat(self.df['Accept_code']);\n",
    "            data_Orcode=concat(self.df['Ordinary_code']);\n",
    "            data['seqs_code']=concat((data_Docode,data_Accode,data_Orcode[choose_index]),axis=0).tolist();\n",
    "            data_nums=data.shape[0];\n",
    "            doseqs_nums=data_Doseq.shape[0];\n",
    "            acseqs_nums=data_Acseq.shape[0];\n",
    "            data['IsDonor']=concat((np.ones(doseqs_nums,dtype=int),np.zeros(data_nums-doseqs_nums,dtype=int)));\n",
    "            data['IsAcceptor']=concat((np.zeros(doseqs_nums),np.ones(acseqs_nums),np.zeros(data_nums-doseqs_nums-acseqs_nums)));\n",
    "            #保存到硬盘\n",
    "            file=os.path.split(path)[0];\n",
    "            if not os.path.isdir(file):\n",
    "                os.mkdir(file);\n",
    "            data[0:10000].to_csv(path);\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gross-simon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████| 570/570 [00:00<00:00, 30515.71it/s]\n",
      "processing: 100%|██████████| 570/570 [00:00<00:00, 31637.11it/s]\n",
      "processing: 100%|██████████| 570/570 [00:08<00:00, 68.48it/s] \n",
      "processing: 100%|██████████| 570/570 [00:00<00:00, 77385.68it/s]\n",
      "processing: 100%|██████████| 570/570 [00:00<00:00, 67863.22it/s]\n",
      "processing: 100%|██████████| 570/570 [00:05<00:00, 96.32it/s] \n",
      "processing: 100%|██████████| 570/570 [00:00<00:00, 9009.98it/s]\n",
      "processing: 100%|██████████| 570/570 [00:00<00:00, 19538.20it/s]\n",
      "processing: 100%|██████████| 570/570 [00:22<00:00, 24.81it/s]\n"
     ]
    }
   ],
   "source": [
    "#定义滑动窗口\n",
    "chunk_size=11;\n",
    "#生成训练集的特征df\n",
    "training_model=sequence_df(training_set_path,chunk_size)\n",
    "training_df=training_model.feature_df();\n",
    "testing_model=sequence_df(testing_set_path,chunk_size)\n",
    "testing_df=testing_model.feature_df();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "difficult-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path=\"../data/data_ready/training_set.csv\"\n",
    "testing_path=\"../data/data_ready/testing_set.csv\"\n",
    "training_model.to_save(training_path);\n",
    "testing_model.to_save(testing_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "neither-following",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID                                                ADS  \\\n",
      "1  AB002059  9106..9239,9843..9993,11889..11960,16575..1665...   \n",
      "2  AB005803  2301..2483,5205..5321,6208..6298,7892..8058,90...   \n",
      "3  AB005990  1..195,845..1035,1543..1745,1831..2031,2116..2...   \n",
      "4  AB009589                            8540..9479,10624..10949   \n",
      "\n",
      "                                            sequence  \\\n",
      "1  ggtgaaacctcatctctactaaaaatacaaaaaattggtcaggcgt...   \n",
      "2  catctgaggccactctctagttcccataatgctaataggaaccatc...   \n",
      "3  atgacccagaccctcaagtacgcctccagagtgttccatcgcgtcc...   \n",
      "4  ccaatcagtttaaattttctagacatttttattctgtctgctctag...   \n",
      "\n",
      "                                        Accept_sites  \\\n",
      "1  [9106, 9843, 11889, 16575, 16841, 17017, 17174...   \n",
      "2       [2301, 5205, 6208, 7892, 9055, 11357, 13312]   \n",
      "3  [1, 845, 1543, 1831, 2116, 2492, 2866, 3234, 3...   \n",
      "4                                      [8540, 10624]   \n",
      "\n",
      "                                         Donor_sites  \n",
      "1  [9239, 9993, 11960, 16650, 16934, 17097, 17315...  \n",
      "2       [2483, 5321, 6298, 8058, 9135, 11458, 14148]  \n",
      "3  [195, 1035, 1745, 2031, 2288, 2664, 2944, 3431...  \n",
      "4                                      [9479, 10949]  \n"
     ]
    }
   ],
   "source": [
    "traning_df=feature_process(traning_df);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "diagnostic-television",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting functools\n",
      "  Using cached functools-0.5.tar.gz (4.9 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /root/anaconda3/envs/datamine/bin/python3.6 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-evk31i_2/functools_5a7a61a6b4aa4ce5a30928ac157edbb8/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-evk31i_2/functools_5a7a61a6b4aa4ce5a30928ac157edbb8/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-gnon_xg4\n",
      "         cwd: /tmp/pip-install-evk31i_2/functools_5a7a61a6b4aa4ce5a30928ac157edbb8/\n",
      "    Complete output (16 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/root/anaconda3/envs/datamine/lib/python3.6/site-packages/setuptools/__init__.py\", line 3, in <module>\n",
      "        from fnmatch import fnmatchcase\n",
      "      File \"/root/anaconda3/envs/datamine/lib/python3.6/fnmatch.py\", line 14, in <module>\n",
      "        import re\n",
      "      File \"/root/anaconda3/envs/datamine/lib/python3.6/re.py\", line 122, in <module>\n",
      "        import enum\n",
      "      File \"/root/anaconda3/envs/datamine/lib/python3.6/enum.py\", line 2, in <module>\n",
      "        from types import MappingProxyType, DynamicClassAttribute\n",
      "      File \"/root/anaconda3/envs/datamine/lib/python3.6/types.py\", line 171, in <module>\n",
      "        import functools as _functools\n",
      "      File \"/tmp/pip-install-evk31i_2/functools_5a7a61a6b4aa4ce5a30928ac157edbb8/functools.py\", line 34\n",
      "        raise TypeError, 'compose expects at least one argument'\n",
      "                       ^\n",
      "    SyntaxError: invalid syntax\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/22/3c/33589bf30422a92cf8c77054f2cf940ef2acc8a2857e5664045ed75a1c6a/functools-0.5.tar.gz#sha256=596ed8999dee419c0749a41bfdd82e4697e80ea27ee01c716003ef55be9a54c5 (from https://pypi.org/simple/functools/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement functools\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for functools\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b528e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
