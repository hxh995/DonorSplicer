{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40195374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5d76faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WAM:\n",
    "    def __init__(self,chunk_size=11,arr_length=2,init_count=0.5):\n",
    "        self.chunksize=chunk_size;\n",
    "        self.arr_length = arr_length;\n",
    "        #初始化 不考虑阶数的 weight_matrix/possibility_matrix\n",
    "        self.init_ord_matrix=pd.DataFrame(np.full((arr_length-1,4),init_count),columns=['a','c','g','t']);\n",
    "        self.pos_ord_weights=pd.DataFrame(np.zeros((arr_length-1,4)),columns=['a','c','g','t']);\n",
    "        self.neg_ord_weights=pd.DataFrame(np.zeros((arr_length-1,4)),columns=['a','c','g','t']);\n",
    "        #初始化 考虑阶数 的 weight_matrix/possibility_matrix\n",
    "        self.nucleo_arrays=self.arr_length_name(arr_length);\n",
    "        #去除初始0:arr_length-1 行 通过阶数计算概率的权力\n",
    "        init_matrix=pd.DataFrame(np.full((chunk_size,4**arr_length),init_count),columns=self.nucleo_arrays);\n",
    "        init_matrix[0:self.arr_length-1]=np.NaN\n",
    "        self.init_matrix=init_matrix;\n",
    "        self.positive_weights=pd.DataFrame(np.zeros((chunk_size,4**arr_length)),columns=self.arr_length_name(arr_length));\n",
    "        self.negative_weights=pd.DataFrame(np.zeros((chunk_size,4**arr_length)),columns=self.arr_length_name(arr_length));\n",
    "        \n",
    "    ##to initialize the name of the columns of the weight_matrix\n",
    "    def arr_length_name(self,arr_length):\n",
    "        bases=['a','c','g','t'];\n",
    "        columns_name=reduce(lambda x,y: [i+j for i in x for j in y] ,[bases]*arr_length);\n",
    "        return columns_name;\n",
    "    # to fit the weight_martix of the trainging data\n",
    "    def fit(self,data,labels):\n",
    "        pos_seqs=data[labels==1].copy().reset_index(drop=True).str.lower();\n",
    "        neg_seqs=data[labels==0].copy().reset_index(drop=True).str.lower();\n",
    "        #to initialize ord_weights and arr_weights\n",
    "        if pos_seqs.shape[0] > 0:\n",
    "            print(\"The model is fitting with the positive data...\")\n",
    "            self.pos_ord_weights += self.count_weights(pos_seqs,self.init_ord_matrix);\n",
    "            self.positive_weights += self.count_weights(pos_seqs,self.init_matrix);\n",
    "            #to normalize by row\n",
    "            #self.pos_ord_weights=self.pos_ord_weights.apply(lambda x:x/x.sum(),axis=0);\n",
    "            self.positive_weights=self.positive_weights.apply(lambda x:x/x.sum(),axis=0);\n",
    "        if neg_seqs.shape[0] > 0:\n",
    "            print(\"The model is fitting with the negative data...\")\n",
    "            self.neg_ord_weights += self.count_weights(neg_seqs,self.init_ord_matrix);\n",
    "            self.negative_weights += self.count_weights(neg_seqs,self.init_matrix);\n",
    "            # to normalize by row\n",
    "            #self.neg_ord_weights=self.neg_ord_weights.apply(lambda x:x/x.sum(),axis=0);\n",
    "            self.negative_weights=self.negative_weights.apply(lambda x:x/x.sum(),axis=0);\n",
    "        \n",
    "        \n",
    "        #to normalize\n",
    "    def count_weights(self,seqs,init_matrix):\n",
    "        weight_matrix=init_matrix.copy();\n",
    "        tqdm.pandas(desc='processing...')\n",
    "        weight_matrix=weight_matrix.progress_apply(lambda x:x + (self.count_base_nums(seqs,x.name)),axis=0);\n",
    "        weight_matrix=weight_matrix.progress_apply(lambda x:x/x.sum(),axis=1)\n",
    "        return weight_matrix;\n",
    "    def count_base_nums(self,seqs,base):    \n",
    "        base_pat=re.compile(pattern=base);\n",
    "        # to calculate the nums of the index of base\n",
    "        find_base=lambda x:[i.span()[1] for i in base_pat.finditer(x,overlapped=True)]\n",
    "        base_index=seqs.apply(find_base);\n",
    "        base_index=reduce(lambda x,y:x+y,base_index)\n",
    "        base_nums=[base_index.count(i) for i in range(1,self.chunksize+1)];\n",
    "        return pd.Series(base_nums);\n",
    "    ## to predict the testing data\n",
    "    def predict_scores(self,data):\n",
    "        probas_matrix=self.predict_probas(data);\n",
    "        score = np.log(probas_matrix['Pos_probas']/probas_matrix['Neg_probas']);\n",
    "        return score;\n",
    "    def predict_probas(self,seqs):\n",
    "        tqdm.pandas(desc='processing...');\n",
    "        scores=seqs.progress_apply(self.seq_probas).tolist();\n",
    "        probas = pd.DataFrame(scores,columns=['Pos_probas','Neg_probas']);\n",
    "        #to normalize\n",
    "        return probas.progress_apply(lambda x:x/x.sum(),axis=1);\n",
    "    def seq_probas(self,seq):\n",
    "        pos_ord_weights=self.pos_ord_weights;\n",
    "        neg_ord_weights=self.neg_ord_weights;\n",
    "        positive_weights=self.positive_weights;\n",
    "        negative_weights=self.negative_weights;\n",
    "        pos_ord_probas=[pos_ord_weights.loc[i,seq[i]] for i in range(0,self.arr_length-1)];\n",
    "        neg_ord_probas=[neg_ord_weights.loc[i,seq[i]] for i in range(0,self.arr_length-1)];\n",
    "        positive_probas=[positive_weights.loc[i-1,seq[i-self.arr_length:i]] for i in range(self.arr_length,len(seq))];\n",
    "        negative_probas=[negative_weights.loc[i-1,seq[i-self.arr_length:i]] for i in range(self.arr_length,len(seq))];\n",
    "        positive_denove_probas=pos_ord_probas + positive_probas;\n",
    "        negative_denove_probas=neg_ord_probas + negative_probas;\n",
    "        pos_denove_probas=reduce(lambda x,y:x*y,positive_denove_probas);\n",
    "        neg_denove_probas=reduce(lambda x,y:x*y,negative_denove_probas);\n",
    "        return [pos_denove_probas,neg_denove_probas];\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "61c25fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing...: 100%|██████████| 4/4 [00:00<00:00, 39.38it/s]\n",
      "processing...: 100%|██████████| 11/11 [00:00<00:00, 2968.56it/s]\n",
      "processing...:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is fitting with the positive data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing...: 100%|██████████| 16/16 [00:00<00:00, 112.54it/s]\n",
      "processing...: 100%|██████████| 11/11 [00:00<00:00, 2777.18it/s]\n",
      "processing...:  50%|█████     | 2/4 [00:00<00:00, 13.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is fitting with the negative data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing...: 100%|██████████| 4/4 [00:00<00:00,  7.39it/s]\n",
      "processing...: 100%|██████████| 11/11 [00:00<00:00, 2776.01it/s]\n",
      "processing...: 100%|██████████| 16/16 [00:00<00:00, 25.70it/s]\n",
      "processing...: 100%|██████████| 11/11 [00:00<00:00, 3158.79it/s]\n"
     ]
    }
   ],
   "source": [
    "model_test=WAM(arr_length=2);\n",
    "#print(model_test.init_matrix)\n",
    "#print(model_test.positive_weights);\n",
    "training_data=pd.read_csv('../data/data_ready/training_set.csv');\n",
    "testing_data=pd.read_csv('../data/data_ready/testing_set.csv');\n",
    "model_test.fit(training_data['seqs'],training_data['IsDonor'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "76338900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing...: 100%|██████████| 10000/10000 [00:01<00:00, 7568.82it/s]\n",
      "processing...: 100%|██████████| 10000/10000 [00:02<00:00, 4073.34it/s]\n"
     ]
    }
   ],
   "source": [
    "#print(model_test.pos_ord_weights);\n",
    "#print(model_test.positive_weights);\n",
    "scores=model_test.predict_scores(testing_data['seqs']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0f4c136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1935\n",
      "2646\n"
     ]
    }
   ],
   "source": [
    "test=[i for i in scores if i >5];\n",
    "print(len(test));\n",
    "seqs=testing_data['seqs']\n",
    "seqs=seqs[testing_data['IsDonor']==1];\n",
    "print(len(seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38329fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import MmhcEstimator, ConstraintBasedEstimator, MaximumLikelihoodEstimator, K2Score, BayesianEstimator, BDeuScore, BicScore\n",
    "from pgmpy.models import BayesianModel\n",
    "class Bayesian_network:\n",
    "    def __init__(self,StructureEstimator=ConstraintBasedEstimator,param_estrimator=BayesianEstimator,chunk_size=11):\n",
    "        self.struct_estrimator=StructureEstimator;\n",
    "        self.param_estrimator=param_estrimator;\n",
    "        self.bn_model=BayesianModel();\n",
    "        self.chunk_size=chunk_size;\n",
    "        self.half_seq=int((self.chunk_size-1)/2);\n",
    "    def process_seqs(self,seqs,label):\n",
    "        seqs_list=[list(seq) for seq in seqs];\n",
    "        #print(seqs_list);\n",
    "        #str why?\n",
    "        df=pd.DataFrame(seqs_list,columns=[str(i) for i in range((-1)*self.half_seq,self.half_seq+1)]);\n",
    "        if label.empty:\n",
    "            return df;\n",
    "        else:\n",
    "            df['L']=label.reset_index(drop=True);\n",
    "            return df;\n",
    "    def get_state_names(self):\n",
    "        names={str(i):list('acgt') for i in range((-1)*self.half_seq,self.half_seq+1)};\n",
    "        names['L']=[0,1];\n",
    "        return names;\n",
    "    def process_DAG(self,DAG):\n",
    "        edges=DAG.edges;\n",
    "        print(edges);\n",
    "        wrong_edges=[i for i in edges if i[0]=='L'];\n",
    "        correct_edges=[(i[1],i[0]) for i in wrong_edges];\n",
    "        DAG.remove_edges_from(wrong_edges);\n",
    "        DAG.add_edges_from(correct_edges);\n",
    "        return DAG;\n",
    "    def fit(self,seqs,label,sign_level=0.02):\n",
    "        \n",
    "        ##process seqs with label to get DAG\n",
    "        data=self.process_seqs(seqs,label);\n",
    "        pre_DAG=data;\n",
    "        #print(pre_DAG);\n",
    "        \n",
    "        ##get the state_names for fit\n",
    "        ##state_names:A dict indicating to show the stats that the variable can take\n",
    "        state_names=self.get_state_names()\n",
    "        #print(stat_names);\n",
    "        \n",
    "        ##structure learning\n",
    "        print('The model is learning the structure through {}'.format(self.struct_estrimator));\n",
    "        if pre_DAG.shape[0] != 0:\n",
    "            struc_estr = self.struct_estrimator(pre_DAG, state_names=state_names);\n",
    "            DAG = struc_estr.estimate(significance_level=sign_level);\n",
    "            DAG = self.process_DAG(DAG);\n",
    "            #add the edges and nodes to the bn_model \n",
    "            self.bn_model.add_edges_from(DAG.edges);\n",
    "            self.bn_model.add_nodes_from([node for node in pre_DAG.columns if not self.bn_model.has_node([node])]);\n",
    "        else:\n",
    "            print(\"something wrong with your data,please check it before using the model again\\n\");\n",
    "            return;\n",
    "        print(\"The structure has already done！\\n\");\n",
    "        #The model is fitting;\n",
    "        print(\"The model is learning through {}\".format(self.param_estrimator));\n",
    "        self.bn_model.fit(data,estimator=self.param_estrimator,state_names=state_names);\n",
    "        print(\"fitting is done\")\n",
    "    def predict_classes(self, data, T):\n",
    "        scores = self.predict_scores(data)\n",
    "        print(scores);\n",
    "        classes = pd.Series(np.zeros(scores.shape, dtype=int));# init\n",
    "        #print(classes);\n",
    "        classes[scores > T] = 1\n",
    "        print(classes);\n",
    "        return classes;\n",
    "    def predict_probas(self,seqs):\n",
    "        empty_label=pd.DataFrame()\n",
    "        data=self.process_seqs(seqs,empty_label);\n",
    "        probas=self.bn_model.predict_probability(data);\n",
    "        #print(probas);\n",
    "        return probas;\n",
    "    def predict_scores(self, data):\n",
    "        probas = self.predict_probas(data)\n",
    "        scores = np.log( probas['L_1'] / probas['L_0'] )\n",
    "        return scores\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f48f5493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is learning the structure through <class 'pgmpy.estimators.ConstraintBasedEstimator.ConstraintBasedEstimator'>\n",
      "[('-5', '-4'), ('-4', '-2'), ('-3', '-4'), ('-3', '-2'), ('0', '-1'), ('1', '4'), ('1', '0'), ('2', '1'), ('2', '3'), ('3', '4'), ('5', '4'), ('L', '4'), ('L', '0'), ('L', '1'), ('L', '2')]\n",
      "The structure has already done！\n",
      "\n",
      "The model is learning through <class 'pgmpy.estimators.BayesianEstimator.BayesianEstimator'>\n",
      "fitting is done\n"
     ]
    }
   ],
   "source": [
    "model_test_bn=Bayesian_network();\n",
    "training_data=pd.read_csv('../data/data_ready/training_set.csv');\n",
    "testing_data=pd.read_csv('../data/data_ready/testing_set.csv');\n",
    "model_test_bn.fit(seqs=training_data['seqs'],label=training_data['IsDonor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9820d283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       3.438576\n",
      "1       4.558635\n",
      "2       4.558635\n",
      "3       2.057679\n",
      "4      -2.364179\n",
      "          ...   \n",
      "4994   -2.509320\n",
      "4995   -2.509320\n",
      "4996   -7.887359\n",
      "4997   -2.424785\n",
      "4998   -8.184514\n",
      "Length: 4999, dtype: float64\n",
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       0\n",
      "       ..\n",
      "4994    0\n",
      "4995    0\n",
      "4996    0\n",
      "4997    0\n",
      "4998    0\n",
      "Length: 4999, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "model_test_bn.predict_classes(testing_data['seqs'][1:5000],1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be6080c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#!easy_install --upgrade pip\n",
    "#!pip install sklearn\n",
    "training_data=pd.read_csv('../data/data_ready/training_set.csv');\n",
    "testing_data=pd.read_csv('../data/data_ready/testing_set.csv')\n",
    "test=eval(testing_data['seqs_code'].iloc[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4349607",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'literal_eva'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-72249212997c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mast\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mliteral_eva\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'literal_eva'"
     ]
    }
   ],
   "source": [
    "from ast import literal_eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a623c098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): | modprobe: FATAL: Module nvidia not found in directory /lib/modules/4.4.0-19041-Microsoft\n",
      "failed\n",
      "\n",
      "ProxyError: Conda cannot proceed due to an error in your proxy configuration.\n",
      "Check for typos and other configuration errors in any '.netrc' file in your home directory,\n",
      "any environment variables ending in '_PROXY', and any other system-wide proxy\n",
      "configuration settings.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ce8b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "class SVP(svm.SVC):\n",
    "    def pre_process(self,data):\n",
    "        seq_list=eval(data);\n",
    "        to_format_arr = lambda data: np.array([np.array(i) for i in data]);\n",
    "        return to_format_arr(seq_list);\n",
    "    def predict_classes(self, data):\n",
    "        return self.predict(data)\n",
    "    \n",
    "    def predict_probas(self, data):\n",
    "        classes = self.predict_classes(data)\n",
    "        print(classes);\n",
    "        probas_tem = np.eye(2) + 0.01\n",
    "        print(probas_tem)\n",
    "        probas = np.array([probas_tem[int(i)] for i in classes])\n",
    "        print(probas.T);\n",
    "        return (probas.T / probas.T.sum(axis=0)).T\n",
    "        \n",
    "    def predict_scores(self, data):\n",
    "        probas = self.predict_probas(data)\n",
    "        scores = np.log(probas[:, 1] / probas[:, 0])\n",
    "        return scores\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
